{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "#####################################################################\n",
    "# This script presents SPECTATOR mode. In SPECTATOR mode you play and\n",
    "# your agent can learn from it.\n",
    "# Configuration is loaded from \"../../examples/config/<SCENARIO_NAME>.cfg\" file.\n",
    "# \n",
    "# To see the scenario description go to \"../../scenarios/README.md\"\n",
    "# \n",
    "#####################################################################\n",
    "from __future__ import print_function\n",
    "from vizdoom import *\n",
    "from time import sleep\n",
    "\n",
    "game = DoomGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose scenario config file you wish to watch.\n",
    "# Don't load two configs cause the second will overrite the first one.\n",
    "# Multiple config files are ok but combining these ones doesn't make much sense.\n",
    "\n",
    "game.load_config(\"../../examples/config/basic.cfg\")\n",
    "\n",
    "imgs = []\n",
    "actions=[]\n",
    "# game.load_config(\"../../examples/config/deadly_corridor.cfg\")\n",
    "# game.load_config(\"../../examples/config/deathmatch.cfg\")\n",
    "#game.load_config(\"../../examples/config/defend_the_center.cfg\")\n",
    "#game.load_config(\"../../examples/config/defend_the_line.cfg\")\n",
    "#game.load_config(\"../../examples/config/health_gathering.cfg\")\n",
    "#game.load_config(\"../../examples/config/my_way_home.cfg\")\n",
    "#game.load_config(\"../../examples/config/predict_position.cfg\")\n",
    "#game.load_config(\"../../examples/config/take_cover.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import toimage\n",
    "images = np.empty([80,80,300])\n",
    "# fp = np.memmap(filename, dtype='float32', mode='w+', shape=(3, 240, 320, 300,1000))\n",
    "ep = 0\n",
    "from PIL import Image\n",
    "# index = np.empty([2, 1])\n",
    "images = np.empty((80,80, 1))\n",
    "index = np.zeros((1,2))\n",
    "rew_step = [0]\n",
    "actions = np.zeros((1,3))\n",
    "rewards = [0]\n",
    "# index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enables spectator mode, so you can play. Sounds strange but it is agent who is supposed to watch not you.\n",
    "game.set_window_visible(True)\n",
    "game.set_mode(Mode.SPECTATOR)\n",
    "frame_sk = 1\n",
    "\n",
    "game.init()\n",
    "\n",
    "episodes = 400\n",
    "#     index = np.empty([1, 1])\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "for i in range(episodes):\n",
    "\n",
    "    print(\"Episode #\" +str(i+1))\n",
    "\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "\n",
    "        s = game.get_state()\n",
    "        img = s.image_buffer\n",
    "        misc = s.game_variables\n",
    "\n",
    "        game.advance_action()\n",
    "        a = game.get_last_action()\n",
    "        r = game.get_last_reward()\n",
    "        \n",
    "        if (s.number % frame_sk == 0):\n",
    "            im_ar = np.array(toimage(img).resize((80,80), Image.ANTIALIAS).convert('L'))\n",
    "            images = np.dstack((images, im_ar))\n",
    "            actions = np.append(actions, np.atleast_2d(a), axis=0)\n",
    "            rew_step.append(r)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "#         imgs.append(img)\n",
    "#         actions.append(a)\n",
    "\n",
    "        #print(\"state #\"+str(s.number))\n",
    "        #print(\"game variables: \", misc)\n",
    "        #print(\"action:\", a)\n",
    "        #print(\"reward:\",r)\n",
    "        #print(\"=====================\")\n",
    "\n",
    "    \n",
    "#     print(\"episode finished!\")\n",
    "#     print(\"final index\", (s.number - s.number %frame_sk)/frame_sk)\n",
    "#     ind = (s.number - s.number %frame_sk)/ frame_sk\n",
    "#     start_ind = 239\n",
    "#     if ep == 0:\n",
    "#         start_ind = 1\n",
    "#     else:\n",
    "#         start_ind = index[-1, 1]+1\n",
    "#     index = np.append(index, np.atleast_2d([start_ind,start_ind + ind -1]), axis=0)\n",
    "#     print(\"total reward:\", game.get_total_reward())\n",
    "#     rewards.append(game.get_total_reward())\n",
    "#     print(\"************************\")\n",
    "    if i %20 == 0 :\n",
    "        print(\"episode #\", i)\n",
    "    sleep(2.0)\n",
    "\n",
    "    ep += 1\n",
    "\n",
    "game.close()\n",
    "# fp[:,:,:,:,ep] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(rew_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(actions.sum(axis = 1) != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = index.astype(int)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images[:,:,index[1,0]:index[1,1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rew_step.count(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions_new[:,1] = actions[:,2]\n",
    "actions_new[:,2] = actions[:,1]\n",
    "actions_new[:,3] = actions[:,0]\n",
    "actions_new[:,0] = 1- np.sum(actions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices_not_missing = [i for i, x in enumerate(rew_step) if x != -6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_action = actions_new[indices_not_missing, :]\n",
    "sub_image = images[:,:,indices_not_missing]\n",
    "\n",
    "clear_action = sub_action[sub_action[:,0] == 0, :]\n",
    "clear_image = sub_image[:,:,sub_action[:,0] == 0]\n",
    "print(clear_action.shape,clear_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions_new = np.zeros((actions.shape[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions_new[:,1] = actions[:,2]\n",
    "actions_new[:,2] = actions[:,1]\n",
    "actions_new[:,3] = actions[:,0]\n",
    "actions_new[:,0] = 1- np.sum(actions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rew_step = map(int, rew_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(data = [pickle.dumps(clear_image), pickle.dumps(clear_action)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ig1 = open(\"images1.txt\",'w')actions1.txt\n",
    "pickle.dump(clear_image, open(\"images1.txt\",'w') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(clear_action, open(\"actions1.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = open(\"data1.csv\", 'a')\n",
    "df.to_csv(target, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_res = pd.read_csv(\"data1.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "images = pickle.loads(df_res.loc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = pickle.loads(df_res.loc[0,2])\n",
    "actions = pickle.loads(df_res.loc[0,3])\n",
    "actions_new = pickle.loads(df_res.loc[0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS='floatX=float32'\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "clear_image = pickle.load( open( \"images1.txt\", \"rb\" ) )\n",
    "clear_action = pickle.load( open( \"actions1.txt\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6156, 80, 80), (6156, 4))\n"
     ]
    }
   ],
   "source": [
    "# images = pickle.loads(df_res.loc[0,1])\n",
    "images = np.rot90(np.flip(np.swapaxes(np.swapaxes(clear_image, 2,0), 0,1),1),k=3)\n",
    "print(images.shape,clear_action.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sub_action = actions_new[actions_new[:,0] == 0, :]\n",
    "# sub_image = images[actions_new[:,0] == 0, :]\n",
    "# sub_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "\n",
    "input_X = T.tensor4(\"X\")\n",
    "\n",
    "#размерность входа (None означает \"может изменяться\")\n",
    "input_shape = (1,80,80)\n",
    "\n",
    "target_y = T.fmatrix(\"target Y integer\")\n",
    "output_shape = [None,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #входной слой (вспомогательный)\n",
    "# input_layer = lasagne.layers.InputLayer(shape = input_shape,input_var=input_X)\n",
    "\n",
    "# #полносвязный слой, который принимает на вход input layer и имеет 100 нейронов.\n",
    "# # нелинейная функция - сигмоида как в логистической регрессии\n",
    "# # слоям тоже можно давать имена, но это необязательно\n",
    "# dense_1 = lasagne.layers.DenseLayer(input_layer,num_units=50,\n",
    "#                                    nonlinearity = lasagne.nonlinearities.sigmoid,\n",
    "#                                    name = \"hidden_dense_layer\")\n",
    "\n",
    "# #ВЫХОДНОЙ полносвязный слой, который принимает на вход dense_1 и имеет 10 нейронов -по нейрону на цифру\n",
    "# #нелинейность - softmax - чтобы вероятности всех цифр давали в сумме 1\n",
    "# dense_output = lasagne.layers.DenseLayer(dense_1,num_units = 4,\n",
    "#                                         nonlinearity = lasagne.nonlinearities.softmax,\n",
    "#                                         name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.init import GlorotUniform, Constant\n",
    "from lasagne.layers import Conv2DLayer, InputLayer, DenseLayer, MaxPool2DLayer, get_output, get_all_params, \\\n",
    "    get_all_param_values, set_all_param_values\n",
    "from lasagne.nonlinearities import rectify\n",
    "from lasagne.objectives import squared_error\n",
    "from lasagne.updates import rmsprop\n",
    "\n",
    "input_layer = InputLayer(shape = (None,)+input_shape,input_var=input_X)\n",
    "\n",
    "# Adds 3 convolutional layers, each followed by a max pooling layer.\n",
    "dqn = Conv2DLayer(input_layer, num_filters=32, filter_size=[8, 8],\n",
    "                  nonlinearity=rectify, W=GlorotUniform(\"relu\"),\n",
    "                  b=Constant(.1))\n",
    "dqn = MaxPool2DLayer(dqn, pool_size=[2, 2])\n",
    "dqn = Conv2DLayer(dqn, num_filters=64, filter_size=[5, 5],\n",
    "                  nonlinearity=rectify, W=GlorotUniform(\"relu\"),\n",
    "                  b=Constant(.1))\n",
    "dqn = MaxPool2DLayer(dqn, pool_size=[2, 2])\n",
    "dqn = Conv2DLayer(dqn, num_filters=64, filter_size=[4, 4],\n",
    "                  nonlinearity=rectify, W=GlorotUniform(\"relu\"),\n",
    "                  b=Constant(.1))\n",
    "\n",
    "dqn = MaxPool2DLayer(dqn, pool_size=[2, 2])\n",
    "dqn = Conv2DLayer(dqn, num_filters=64, filter_size=[3, 3],\n",
    "                  nonlinearity=rectify, W=GlorotUniform(\"relu\"),\n",
    "                  b=Constant(.1))\n",
    "dqn = MaxPool2DLayer(dqn, pool_size=[2, 2])\n",
    "# Adds a single fully connected layer.\n",
    "dqn = DenseLayer(dqn, num_units=512, nonlinearity=rectify, W=GlorotUniform(\"relu\"),\n",
    "                 b=Constant(.1))\n",
    "\n",
    "# Adds a single fully connected layer which is the output layer.\n",
    "# (no nonlinearity as it is for approximating an arbitrary real function)\n",
    "dense_output = DenseLayer(dqn,num_units = 4,\n",
    "                                        nonlinearity = lasagne.nonlinearities.softmax,\n",
    "                                        name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#предсказание нейронки (theano-преобразование)\n",
    "y_predicted = lasagne.layers.get_output(dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b, W, b, W, b, output.W, output.b]\n"
     ]
    }
   ],
   "source": [
    "#все веса нейронки (shared-переменные)\n",
    "all_weights = lasagne.layers.get_all_params(dense_output)\n",
    "print (all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: You are creating a TensorVariable with float64 dtype. You requested an action via the Theano flag warn_float64={ignore,warn,raise,pdb}.\n"
     ]
    }
   ],
   "source": [
    "#функция ошибки - средняя кроссэнтропия\n",
    "loss = lasagne.objectives.squared_error(y_predicted,target_y).mean()\n",
    "# loss = ((y_predicted - target_y)**2).sum()\n",
    "\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted,target_y).mean()\n",
    "\n",
    "# #сразу посчитать словарь обновлённых значений с шагом по градиенту, как раньше\n",
    "updates_sgd = lasagne.updates.adam(loss, all_weights,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#функция, которая обучает сеть на 1 шаг и возвращащет значение функции потерь и точности\n",
    "train_fun = theano.function([input_X,target_y],[loss,accuracy,y_predicted],updates= updates_sgd, allow_input_downcast=True)\n",
    "\n",
    "#функция, которая считает точность\n",
    "accuracy_fun = theano.function([input_X],y_predicted, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fun(np.random.rand(1,1,80,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fun([[images[2390]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-b36a98afa22f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2390\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "[[images[2390]]].shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.expand_dims(sub_image, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=True):\n",
    "#     print(\"length input {} length targ {}\".format(len(inputs), len(targets)))\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2052, 80, 80)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x): return x%3== 0\n",
    "ind7 = filter(f, range(clear_action.shape[0]-1))\n",
    "\n",
    "images[ind7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1000 took 0.717s\n",
      "  training loss (in-iteration):\t\t0.286500\n",
      "  train accuracy:\t\t42.70 %\n",
      "Epoch 2 of 1000 took 0.870s\n",
      "  training loss (in-iteration):\t\t0.288500\n",
      "  train accuracy:\t\t42.30 %\n",
      "Epoch 3 of 1000 took 0.873s\n",
      "  training loss (in-iteration):\t\t0.287250\n",
      "  train accuracy:\t\t42.55 %\n",
      "Epoch 4 of 1000 took 0.874s\n",
      "  training loss (in-iteration):\t\t0.287750\n",
      "  train accuracy:\t\t42.45 %\n",
      "Epoch 5 of 1000 took 0.886s\n",
      "  training loss (in-iteration):\t\t0.289750\n",
      "  train accuracy:\t\t42.05 %\n",
      "Epoch 6 of 1000 took 0.886s\n",
      "  training loss (in-iteration):\t\t0.287250\n",
      "  train accuracy:\t\t42.55 %\n",
      "Epoch 7 of 1000 took 0.875s\n",
      "  training loss (in-iteration):\t\t0.288000\n",
      "  train accuracy:\t\t42.40 %\n",
      "Epoch 8 of 1000 took 0.906s\n",
      "  training loss (in-iteration):\t\t0.286500\n",
      "  train accuracy:\t\t42.70 %\n",
      "Epoch 9 of 1000 took 0.937s\n",
      "  training loss (in-iteration):\t\t0.288250\n",
      "  train accuracy:\t\t42.35 %\n",
      "Epoch 10 of 1000 took 0.880s\n",
      "  training loss (in-iteration):\t\t0.288000\n",
      "  train accuracy:\t\t42.40 %\n",
      "Epoch 11 of 1000 took 0.879s\n",
      "  training loss (in-iteration):\t\t0.286000\n",
      "  train accuracy:\t\t42.80 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-f8b652619e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtrain_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclear_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "images_4 = np.expand_dims(images, axis=1)\n",
    "import time\n",
    "\n",
    "def f(x): return x%3== 0\n",
    "ind7 = filter(f, range(clear_action.shape[0]-1))\n",
    "\n",
    "\n",
    "num_epochs = 1000 #количество проходов по данным\n",
    "\n",
    "batch_size = 1000 #размер мини-батча\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(np.expand_dims(images[ind7], axis=1), clear_action[ind7],batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch, y_pred= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "#     # And a full pass over the validation data:\n",
    "#     val_acc = 0\n",
    "#     val_batches = 0\n",
    "#     for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "#         inputs, targets = batch\n",
    "#         val_acc += accuracy_fun(inputs, targets)\n",
    "#         val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "#     print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "#         val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(inputs[1] == inputs[300]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs[239].reshape(80,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_actions = 4\n",
    "state_dim = (80,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import *\n",
    "import theano.tensor as T\n",
    "\n",
    "#create input variables. We'll support multiple states at once\n",
    "\n",
    "\n",
    "current_states = T.matrix(\"states[batch,units]\")\n",
    "actions = T.ivector(\"action_ids[batch]\")\n",
    "rewards = T.vector(\"rewards[batch]\")\n",
    "next_states = T.matrix(\"next states[batch,units]\")\n",
    "is_end = T.ivector(\"vector[batch] where 1 means that session just ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "#input layer\n",
    "l_states = InputLayer((80,80))\n",
    "\n",
    "dense_1 = DenseLayer(l_states,num_units=100,\n",
    "                                   name = \"hidden_dense_layer\")\n",
    "#output layer\n",
    "l_qvalues = DenseLayer(dense_1,num_units=n_actions,nonlinearity=None)\n",
    "predicted_qvalues = get_output(l_qvalues,{l_states:current_states})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get q-values for ALL actions in current_states\n",
    "\n",
    "#compiling agent's \"GetQValues\" function\n",
    "get_qvalues = theano.function([current_states], predicted_qvalues,\n",
    "    allow_input_downcast=True)\n",
    "#select q-values for chosen actions\n",
    "predicted_qvalues_for_actions = predicted_qvalues[T.arange(actions.shape[0]),actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_qvalues_for_actions = T.matrix(\"our actions\")\n",
    "my_inputs = {\n",
    "    target_qvalues_for_actions: actions_new\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict q-values for next states\n",
    "predicted_next_qvalues = get_output(l_qvalues,{l_states:next_states})\n",
    "\n",
    "\n",
    "#Computing target q-values under \n",
    "gamma = 0.99\n",
    "# target_qvalues_for_actions = rewards + gamma* predicted_next_qvalues.max(axis= 1)\n",
    "    \n",
    "# #zero-out q-values at the end\n",
    "# target_qvalues_for_actions = (1-is_end)*target_qvalues_for_actions\n",
    "\n",
    "# #don't compute gradient over target q-values (consider constant)\n",
    "# target_qvalues_for_actions = theano.gradient.disconnected_grad(target_qvalues_for_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# target_qvalues_for_actions = T.matrix(\"our actions values\")\n",
    "#mean squared error loss function\n",
    "loss = T.mean((predicted_qvalues_for_actions - target_qvalues_for_actions) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all network weights\n",
    "all_weights = get_all_params(l_qvalues,trainable=True)\n",
    "\n",
    "#network updates. Note the small learning rate (for stability)\n",
    "updates = lasagne.updates.sgd(loss,all_weights,learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training function that resembles agent.update(state,action,reward,next_state) \n",
    "#with 1 more argument meaning is_end\n",
    "train_step = theano.function([current_states,actions,next_states,is_end],\n",
    "    allow_input_downcast=True,\n",
    "                             updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon = 0.25 #initial epsilon\n",
    "\n",
    "\n",
    "def generate_session( num   ,t_max=300):\n",
    "    \"\"\"play env with approximate q-learning agent and train it at the same time\"\"\"\n",
    "    \n",
    "#     for i in range()\n",
    "    total_reward = 0\n",
    "    s = images[:,:,index[num,0]]\n",
    "    \n",
    "    for t in range(index[num,0]+1, index[num,1] + 1):\n",
    "        \n",
    "        #get action q-values from the network\n",
    "        q_values = get_qvalues(s)[0] \n",
    "        \n",
    "        if( np.random.random() < epsilon):\n",
    "            a = np.random.choice(n_actions)\n",
    "        else:\n",
    "            a = np.argmax(q_values)\n",
    "        \n",
    "#         a = <sample action with epsilon-greedy strategy>\n",
    "        \n",
    "#         new_s,r,done,info = env.step(a)\n",
    "        new_s = images[:,:,t]\n",
    "#         r = rew_step[t]\n",
    "        \n",
    "        done = [(t == index[num,1] )]\n",
    "        \n",
    "        #train agent one step. Note that we use one-element arrays instead of scalars \n",
    "        #because that's what function accepts.\n",
    "        train_step([s],[a],[new_s],[done])\n",
    "        \n",
    "        total_reward+=r\n",
    "        \n",
    "        s = new_s\n",
    "#         if t = \n",
    "        if done: break\n",
    "            \n",
    "    return total_reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "    \n",
    "rewards = [generate_session(num = j) for j in range(index.shape[0])] #generate new sessions\n",
    "\n",
    "epsilon*=0.95\n",
    "\n",
    "print (\"mean reward:%.3f\\tepsilon:%.5f\"%(np.mean(rewards),epsilon))\n",
    "\n",
    "if np.mean(rewards) > 300:\n",
    "    print (\"You Win!\")\n",
    "    break\n",
    "\n",
    "assert epsilon!=0, \"Please explore environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_im = images[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[tmp_im].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_values = get_qvalues(tmp_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_1 = images.reshape(images.shape[2], 80, 80)\n",
    "\n",
    "img_1 = np.rot90(np.flip(np.swapaxes(images, 2,0),1),k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.rot90(img_1[0,:,:],k=3) == images[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(img_1[14,:,:],k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[:,14,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.rot90(np.flip(np.swapaxes(np.swapaxes(images, 2,0), 0,1),1),k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
